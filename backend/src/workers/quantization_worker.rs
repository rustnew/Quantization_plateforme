

use std::path::PathBuf;
use std::sync::Arc;
use std::time::{Duration, Instant};
use tokio::sync::{Mutex, Semaphore};
use tokio::task;
use uuid::Uuid;
use tracing::{info, warn, error, debug, instrument};
use serde::{Serialize, Deserialize};
use chrono::Utc;

use crate::{
    infrastructure::database::{
        Database,
        JobsRepository,
        SubscriptionsRepository,
        UserRepository,
    },
    infrastructure::storage::StorageService,
    infrastructure::python::PythonRuntime,
    infrastructure::error::{AppError, AppResult},
    core::quantization::{
        QuantizationPipeline,
        QuantizationConfig,
        QuantizationMethod as CoreQuantizationMethod,
    },
    domain::job::{Job, JobStatus, QuantizationMethod},
};

/// Configuration du worker
#[derive(Debug, Clone, Deserialize)]
pub struct WorkerConfig {
    /// Nombre maximum de jobs simultan√©s
    pub max_concurrent_jobs: usize,
    /// Intervalle entre les polling de jobs (secondes)
    pub poll_interval_seconds: u64,
    /// Timeout maximum par job (minutes)
    pub job_timeout_minutes: u64,
    /// Nombre maximum de tentatives par job
    pub max_retries: usize,
    /// R√©pertoire temporaire pour les fichiers
    pub temp_dir: String,
    /// Activer le mode debug (logs verbeux)
    pub debug_mode: bool,
}

impl Default for WorkerConfig {
    fn default() -> Self {
        Self {
            max_concurrent_jobs: 2, // Par d√©faut sur les petites instances
            poll_interval_seconds: 5,
            job_timeout_minutes: 120,
            max_retries: 3,
            temp_dir: "/tmp/quant_worker".to_string(),
            debug_mode: false,
        }
    }
}

/// Worker principal pour le traitement des jobs
pub struct QuantizationWorker {
    config: WorkerConfig,
    db: Database,
    storage: StorageService,
    python_runtime: PythonRuntime,
    // Semaphore pour contr√¥ler les jobs simultan√©s
    concurrency_limiter: Arc<Semaphore>,
    // Mutex pour √©viter les acc√®s concurrents au m√™me job
    active_jobs: Arc<Mutex<std::collections::HashSet<Uuid>>>,
}

impl QuantizationWorker {
    /// Cr√©e une nouvelle instance du worker
    pub fn new(
        config: WorkerConfig,
        db: Database,
        storage: StorageService,
        python_runtime: PythonRuntime,
    ) -> Self {
        Self {
            config: config.clone(),
            db,
            storage,
            python_runtime,
            concurrency_limiter: Arc::new(Semaphore::new(config.max_concurrent_jobs)),
            active_jobs: Arc::new(Mutex::new(std::collections::HashSet::new())),
        }
    }

    /// D√©marre le worker en boucle infinie
    pub async fn start(mut self) -> ! {
        info!("üöÄ Worker de quantification d√©marr√© avec config: {:?}", self.config);
        info!("‚ö° {} jobs simultan√©s maximum", self.config.max_concurrent_jobs);
        info!("‚è±Ô∏è  Intervalle de polling: {} secondes", self.config.poll_interval_seconds);
        
        // Cr√©er le r√©pertoire temporaire si n√©cessaire
        let temp_path = PathBuf::from(&self.config.temp_dir);
        if !temp_path.exists() {
            if let Err(e) = std::fs::create_dir_all(&temp_path) {
                error!("‚ùå Impossible de cr√©er le r√©pertoire temporaire {}: {}", self.config.temp_dir, e);
            } else {
                info!("‚úÖ R√©pertoire temporaire cr√©√©: {}", self.config.temp_dir);
            }
        }
        
        let mut last_heartbeat = Instant::now();
        
        loop {
            // Heartbeat toutes les 30 secondes pour v√©rifier que le worker est actif
            if last_heartbeat.elapsed() > Duration::from_secs(30) {
                info!("üíì Worker heartbeat - {} jobs actifs", self.active_jobs.lock().await.len());
                last_heartbeat = Instant::now();
                
                // V√©rifier les jobs potentiellement bloqu√©s
                self.check_stuck_jobs().await;
            }
            
            // Poller les jobs en attente
            match self.poll_and_process_jobs().await {
                Ok(processed) if processed > 0 => {
                    debug!("‚úÖ {} jobs trait√©s lors de ce cycle", processed);
                },
                Ok(_) => {
                    // Aucun job √† traiter - attente avec backoff
                    tokio::time::sleep(Duration::from_secs(self.config.poll_interval_seconds)).await;
                },
                Err(e) => {
                    error!("‚ùå Erreur lors du polling des jobs: {}", e);
                    // Attente plus longue en cas d'erreur pour √©viter la saturation
                    tokio::time::sleep(Duration::from_secs(15)).await;
                }
            }
        }
    }

    /// Poll la base de donn√©es pour les jobs en attente et les traite
    async fn poll_and_process_jobs(&self) -> AppResult<usize> {
        // R√©cup√©rer les jobs en attente (status = 'queued')
        let jobs_repo = JobsRepository::new(self.db.pool.clone());
        let queued_jobs = jobs_repo.get_by_status(JobStatus::Queued, 10, 0).await?;
        
        if queued_jobs.is_empty() {
            return Ok(0);
        }
        
        debug!("üîç {} jobs en attente trouv√©s", queued_jobs.len());
        
        let mut processed_count = 0;
        
        // Traiter chaque job avec un syst√®me de priorit√©
        for job in queued_jobs {
            // V√©rifier si le job est d√©j√† en cours de traitement
            let mut active_jobs = self.active_jobs.lock().await;
            if active_jobs.contains(&job.id) {
                debug!("‚è∏Ô∏è  Job {} d√©j√† en cours de traitement", job.id);
                continue;
            }
            
            // Ajouter le job √† la liste des jobs actifs
            active_jobs.insert(job.id);
            drop(active_jobs); // Lib√©rer le lock
            
            // Obtenir un permis pour ex√©cuter le job
            let permit = match self.concurrency_limiter.clone().acquire().await {
                Ok(permit) => permit,
                Err(e) => {
                    warn!("‚ö†Ô∏è  Impossible d'obtenir un permis de concurrence: {}", e);
                    // Remettre le job dans la liste des actifs
                    let mut active_jobs = self.active_jobs.lock().await;
                    active_jobs.insert(job.id);
                    continue;
                }
            };
            
            processed_count += 1;
            
            // Traiter le job dans une t√¢che s√©par√©e
            let worker_clone = self.clone();
            let job_clone = job.clone();
            
            task::spawn(async move {
                // D√©marrer le traitement avec timeout
                let timeout = Duration::from_secs(worker_clone.config.job_timeout_minutes * 60);
                
                match tokio::time::timeout(timeout, worker_clone.process_single_job(job_clone)).await {
                    Ok(result) => {
                        match result {
                            Ok(_) => {
                                debug!("‚úÖ Job {} trait√© avec succ√®s", job_clone.id);
                            },
                            Err(e) => {
                                error!("‚ùå √âchec du job {}: {}", job_clone.id, e);
                            }
                        }
                    },
                    Err(_) => {
                        error!("‚è∞ Job {} a expir√© apr√®s {} minutes", job_clone.id, worker_clone.config.job_timeout_minutes);
                        // Marquer le job comme √©chou√©
                        let jobs_repo = JobsRepository::new(worker_clone.db.pool.clone());
                        let _ = jobs_repo.fail_job(&job_clone.id, format!(
                            "Job expir√© apr√®s {} minutes", worker_clone.config.job_timeout_minutes
                        )).await;
                    }
                }
                
                // Lib√©rer les ressources
                let mut active_jobs = worker_clone.active_jobs.lock().await;
                active_jobs.remove(&job_clone.id);
                drop(active_jobs);
                drop(permit);
            });
        }
        
        Ok(processed_count)
    }

    /// Traite un seul job de quantification
    #[instrument(skip_all, fields(job_id = %job.id, user_id = %job.user_id, model_name = %job.model_name))]
    async fn process_single_job(&self, job: Job) -> AppResult<()> {
        info!("üîÑ Traitement du job {} pour l'utilisateur {}", job.id, job.user_id);
        let start_time = Instant::now();
        
        // 1. Mettre √† jour le statut en "processing"
        let jobs_repo = JobsRepository::new(self.db.pool.clone());
        jobs_repo.update_status(&job.id, JobStatus::Processing).await?;
        
        // 2. T√©l√©charger le mod√®le depuis le stockage
        let input_path = self.storage.download_file(&job.input_path).await?;
        info!("üì• Mod√®le t√©l√©charg√©: {:?}, taille: {} Mo", input_path, 
              std::fs::metadata(&input_path)?.len() as f64 / 1_000_000.0);
        
        // 3. Cr√©er le r√©pertoire de sortie
        let output_dir = PathBuf::from(&self.config.temp_dir).join(job.id.to_string());
        if output_dir.exists() {
            std::fs::remove_dir_all(&output_dir)?;
        }
        std::fs::create_dir_all(&output_dir)?;
        
        // 4. Configurer la quantification
        let quant_method = match job.quantization_method {
            QuantizationMethod::Int8 => CoreQuantizationMethod::Int8,
            QuantizationMethod::Int4 => CoreQuantizationMethod::Int4,
            QuantizationMethod::Gptq => CoreQuantizationMethod::Gptq,
            QuantizationMethod::Awq => CoreQuantizationMethod::Awq,
            _ => CoreQuantizationMethod::Int8,
        };
        
        let config = QuantizationConfig {
            method: quant_method.clone(),
            bits: match quant_method {
                CoreQuantizationMethod::Int8 => 8,
                _ => 4,
            },
            group_size: 128,
            use_calibration: true,
            calibration_data_path: Some("/app/data/calibration_data".to_string()),
            output_formats: vec!["onnx".to_string(), "gguf".to_string()],
        };
        
        // 5. Ex√©cuter le pipeline de quantification
        info!("‚öôÔ∏è  D√©marrage de la quantification {}...", quant_method);
        
        match quant_method {
            CoreQuantizationMethod::Int8 => {
                self.quantize_onnx(&job, &input_path, &output_dir, &config).await?;
            },
            CoreQuantizationMethod::Int4 | 
            CoreQuantizationMethod::Gptq | 
            CoreQuantizationMethod::Awq => {
                self.quantize_pytorch(&job, &input_path, &output_dir, &config).await?;
            },
            _ => {
                return Err(AppError::BadRequest("M√©thode de quantification non support√©e".to_string()));
            }
        }
        
        // 6. Calculer le temps de traitement
        let processing_time = start_time.elapsed().as_secs() as i32;
        let processing_time_str = format!("{:.1} minutes", processing_time as f32 / 60.0);
        info!("‚úÖ Job {} compl√©t√© en {}", job.id, processing_time_str);
        
        // 7. G√©n√©rer le rapport d√©taill√©
        self.generate_and_save_report(&job, processing_time).await?;
        
        // 8. Nettoyer les fichiers temporaires
        self.cleanup_temp_files(&input_path, &output_dir).await?;
        
        Ok(())
    }

    /// Quantifie un mod√®le ONNX
    async fn quantize_onnx(
        &self,
        job: &Job,
        input_path: &PathBuf,
        output_dir: &PathBuf,
        config: &QuantizationConfig,
    ) -> AppResult<()> {
        // Cr√©er le pipeline de quantification
        let pipeline = QuantizationPipeline::new(
            self.db.clone(),
            self.storage.clone(),
            self.python_runtime.clone(),
        );
        
        // Ex√©cuter la quantification
        let result = pipeline.quantize_onnx(input_path, output_dir, config).await?;
        
        // Upload du r√©sultat
        let output_path = PathBuf::from(&result.quantized_path);
        let download_url = self.storage.upload_file(&output_path).await?;
        
        // Mettre √† jour le job
        let jobs_repo = JobsRepository::new(self.db.pool.clone());
        jobs_repo.complete_job(
            &job.id,
            result.quantized_size_bytes as i64,
            download_url,
        ).await?;
        
        info!("üì§ R√©sultat ONNX upload√©: {}", result.quantized_path);
        
        Ok(())
    }

    /// Quantifie un mod√®le PyTorch
    async fn quantize_pytorch(
        &self,
        job: &Job,
        input_path: &PathBuf,
        output_dir: &PathBuf,
        config: &QuantizationConfig,
    ) -> AppResult<()> {
        // Cr√©er le pipeline de quantification
        let pipeline = QuantizationPipeline::new(
            self.db.clone(),
            self.storage.clone(),
            self.python_runtime.clone(),
        );
        
        // Ex√©cuter la quantification
        let result = pipeline.quantize_pytorch(input_path, output_dir, config).await?;
        
        // Upload du r√©sultat
        let output_path = PathBuf::from(&result.quantized_path);
        let download_url = self.storage.upload_file(&output_path).await?;
        
        // Mettre √† jour le job
        let jobs_repo = JobsRepository::new(self.db.pool.clone());
        jobs_repo.complete_job(
            &job.id,
            result.quantized_size_bytes as i64,
            download_url,
        ).await?;
        
        info!("üì§ R√©sultat PyTorch upload√©: {}", result.quantized_path);
        
        Ok(())
    }

    /// G√©n√®re et sauvegarde le rapport de quantification
    async fn generate_and_save_report(&self, job: &Job, processing_time: i32) -> AppResult<()> {
        // R√©cup√©rer le job mis √† jour
        let jobs_repo = JobsRepository::new(self.db.pool.clone());
        let completed_job = jobs_repo.get_by_id(&job.id).await?;
        
        // G√©n√©rer le rapport
        let reduction_percent = completed_job.reduction_percent.unwrap_or(0.0);
        let original_size_gb = completed_job.original_size_bytes as f64 / 1_073_741_824.0;
        let quantized_size_gb = completed_job.quantized_size_bytes.unwrap_or(0) as f64 / 1_073_741_824.0;
        
        // Estimer les √©conomies de co√ªts
        let cost_savings_percent = if completed_job.quantization_method == QuantizationMethod::Int8 {
            40.0
        } else {
            70.0
        };
        
        let report = serde_json::json!({
            "job_id": job.id,
            "user_id": job.user_id,
            "model_name": job.model_name,
            "quantization_method": format!("{:?}", completed_job.quantization_method),
            "original_size_gb": original_size_gb,
            "quantized_size_gb": quantized_size_gb,
            "reduction_percent": reduction_percent,
            "processing_time_seconds": processing_time,
            "quality_loss_percent": 0.8, // Valeur temporaire - √† remplacer par une validation r√©elle
            "latency_improvement_percent": 65.0, // Valeur temporaire
            "estimated_cost_savings_percent": cost_savings_percent,
            "download_url": completed_job.download_url,
            "created_at": Utc::now(),
            "hardware_recommendations": {
                "minimum_ram_gb": if reduction_percent > 70.0 { 8 } else { 16 },
                "recommended_gpu": if completed_job.quantization_method == QuantizationMethod::Int8 { 
                    "RTX 3060" 
                } else { 
                    "RTX 3090 ou sup√©rieur" 
                }
            }
        });
        
        // Sauvegarder dans la base de donn√©es
        let query = sqlx::query!(
            r#"
            INSERT INTO quantization_reports (
                job_id, original_perplexity, quantized_perplexity, 
                quality_loss_percent, latency_improvement_percent, cost_savings_percent
            )
            VALUES ($1, $2, $3, $4, $5, $6)
            "#,
            job.id,
            15.8, // perplexity originale temporaire
            16.2, // perplexity quantifi√©e temporaire
            0.8,  // perte de qualit√© temporaire
            65.0, // am√©lioration latence temporaire
            cost_savings_percent
        );
        
        query.execute(&*self.db.pool).await?;
        
        // Logger le rapport
        info!("üìä Rapport de quantification g√©n√©r√© pour le job {}:\n{}", job.id, serde_json::to_string_pretty(&report)?);
        
        Ok(())
    }

    /// V√©rifie les jobs potentiellement bloqu√©s
    async fn check_stuck_jobs(&self) {
        let jobs_repo = JobsRepository::new(self.db.pool.clone());
        
        // R√©cup√©rer les jobs en traitement depuis plus de 30 minutes
        let cutoff_time = Utc::now() - chrono::Duration::minutes(30);
        
        match sqlx::query_as!(
            Job,
            r#"
            SELECT 
                id, user_id, model_name, original_size_bytes, quantized_size_bytes,
                quantization_method::VARCHAR as "quantization_method: QuantizationMethod",
                status::VARCHAR as "status: JobStatus",
                error_message, reduction_percent, download_url,
                created_at, updated_at
            FROM jobs
            WHERE status = $1 AND updated_at < $2
            "#,
            JobStatus::Processing.to_string(),
            cutoff_time
        )
        .fetch_all(&self.db.pool)
        .await
        {
            Ok(stuck_jobs) if !stuck_jobs.is_empty() => {
                warn!("‚ö†Ô∏è  {} jobs potentiellement bloqu√©s d√©tect√©s", stuck_jobs.len());
                
                for job in stuck_jobs {
                    error!("üîç Investigating stuck job: {}", job.id);
                    
                    // Essayer de marquer comme √©chou√©
                    let _ = jobs_repo.fail_job(&job.id, "Job bloqu√© - timeout d√©tection".to_string()).await;
                    
                    // Nettoyer les ressources
                    let temp_dir = PathBuf::from(&self.config.temp_dir).join(job.id.to_string());
                    if temp_dir.exists() {
                        if let Err(e) = std::fs::remove_dir_all(&temp_dir) {
                            warn!("‚ö†Ô∏è  Impossible de nettoyer {} pour le job {}: {}", temp_dir.display(), job.id, e);
                        }
                    }
                }
            },
            Ok(_) => {
                // Aucun job bloqu√©
            },
            Err(e) => {
                error!("‚ùå Erreur lors de la v√©rification des jobs bloqu√©s: {}", e);
            }
        }
    }

    /// Nettoie les fichiers temporaires
    async fn cleanup_temp_files(&self, input_path: &PathBuf, output_dir: &PathBuf) -> AppResult<()> {
        if self.config.debug_mode {
            debug!("üîç Mode debug activ√© - pas de nettoyage des fichiers temporaires");
            return Ok(());
        }
        
        // Supprimer le fichier d'entr√©e t√©l√©charg√©
        if input_path.exists() {
            if let Err(e) = std::fs::remove_file(input_path) {
                warn!("‚ö†Ô∏è  Impossible de supprimer {}: {}", input_path.display(), e);
            } else {
                debug!("üóëÔ∏è  Fichier d'entr√©e supprim√©: {}", input_path.display());
            }
        }
        
        // Supprimer le r√©pertoire de sortie
        if output_dir.exists() {
            if let Err(e) = std::fs::remove_dir_all(output_dir) {
                warn!("‚ö†Ô∏è  Impossible de supprimer {}: {}", output_dir.display(), e);
            } else {
                debug!("üóëÔ∏è  R√©pertoire de sortie supprim√©: {}", output_dir.display());
            }
        }
        
        Ok(())
    }
}

/// Initialisation du worker au d√©marrage de l'application
pub async fn start_worker_background(
    config: WorkerConfig,
    db: Database,
    storage: StorageService,
    python_runtime: PythonRuntime,
) -> AppResult<()> {
    info!("üîß Initialisation du worker background...");
    
    let worker = QuantizationWorker::new(
        config,
        db,
        storage,
        python_runtime,
    );
    
    // D√©marrer dans une t√¢che Tokio s√©par√©e
    tokio::spawn(async move {
        worker.start().await;
    });
    
    info!("‚úÖ Worker background d√©marr√© avec succ√®s");
    Ok(())
}
